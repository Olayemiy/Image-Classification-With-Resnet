{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.onnx as onnx\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torchvision import transforms\n",
    "from torchvision import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((80, 80)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.ImageFolder('C:/Users/yyesu/Documents/Deep Learning Project FIles/intel-image-classification/seg_train/seg_train', transform=transforms)\n",
    "test_ds = datasets.ImageFolder('C:/Users/yyesu/Documents/Deep Learning Project FIles/intel-image-classification/seg_test/seg_test', transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_ds, batch_size=20, shuffle=True)\n",
    "testloader = DataLoader(test_ds, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1) #we include stride here because not all the blocks we create are gonna have a stride of 1\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)#inplace means that it will not allocate new memory and change tensors inplace\n",
    "        self.conv2 = nn.Conv2d(out_channels,out_channels, kernel_size=3,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample #this is incase the input and output channels are not the same. it is initiated as none\n",
    "\n",
    "#i was getting errors like:The size of tensor a (90) must match the size of tensor b (94) at non-singleton dimension 3\n",
    "#apperently its because i didnt include padding in the convolution layers.the outputs are supposed to be the same but it wasnt, \n",
    "#because it was getting smaller with each convolution... take note for next time man\n",
    "#\n",
    "    def forward(self, x):\n",
    "        skip_connection = x #input to add to end of block\n",
    "        \n",
    "        x = self.relu(self.bn1(self.conv1(x)))        \n",
    "        x = self.bn2(self.conv2(x))\n",
    "          \n",
    "        if self.downsample:# is not None:\n",
    "            skip_connection = self.downsample(skip_connection)\n",
    "    \n",
    "        x += skip_connection\n",
    "        x = self.relu(x)\n",
    "                \n",
    "        return x\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, block, layers): #block in this case is the resnet block defined above. could have been a bottle neck block if I hadn't chickend out of implementing that\n",
    "        super(ResNet,self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(3,64, 7,stride =1) #remember input is bw not rgb\n",
    "        \n",
    "        self.bn= nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.relu =nn.ReLU(inplace =True)\n",
    "        \n",
    "        #self.max_pool = nn.MaxPool2d(3, stride=2)\n",
    "        \n",
    "        self.in_channels=64\n",
    "        \n",
    "        self.layer1 = self.make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 128, layers[1],2) #stride =2\n",
    "        self.layer3 = self.make_layer(block, 256, layers[2],2)\n",
    "        self.layer4 = self.make_layer(block, 512, layers[3],2)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(512,6)\n",
    "        \n",
    "\n",
    "    def make_layer(self, block, out_channels, num_of_blocks, stride = 1):\n",
    "        \n",
    "        downsample = None\n",
    "        \n",
    "        if (stride != 1) or (self.in_channels != out_channels): \n",
    "            downsample = nn.Sequential(nn.Conv2d(self.in_channels, out_channels,1,stride=stride),\n",
    "                                      nn.BatchNorm2d(out_channels)) #downsample to be applied to the ResnetBlock\n",
    "            \n",
    "        block_layers=[]  #layers of blocks\n",
    "        block_layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        \n",
    "        #change the amount of input channels to output channels for the next set of layers that youll define in __init__\n",
    "        self.in_channels = out_channels\n",
    "        \n",
    "        #the first block is being added separately because the input dimensions may differ, hence the stride and downsampling\n",
    "        for i in range(1, num_of_blocks): #since we already added the first block, we start from the first index\n",
    "            block_layers.append(block(out_channels, out_channels))\n",
    "            \n",
    "        return nn.Sequential(*block_layers) #this iterates over the Block_layers and executes each block in the list\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        #x = self.relu(x)\n",
    "        #x = self.max_pool(x)\n",
    "    \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x=F.softmax(x, dim =1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    \n",
    "    \n",
    "net=ResNet(ResnetBlock, [3,4,6,3]).to(device) #[3,4,6,3] is the number of blocks for each layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb=SummaryWriter(\"runs/Train\")\n",
    "tb_test=SummaryWriter(\"runs/Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer= optim.Adam(net.parameters(), lr =0.001)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"image_scene_classification_3ch_v2.pth\"\n",
    "\n",
    "def train(net):\n",
    "    loss=0\n",
    "    epochs=30\n",
    "    \n",
    "    #...resume learning\n",
    "    #***********comment out if starting training from scratch***********\n",
    "    \n",
    "    checkpoint = torch.load(\"image_scene_classification_3ch.pth\")\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    #*******************************************************************\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        trainloss = 0\n",
    "        traintotal = 0\n",
    "        trainsuccessful = 0\n",
    "        for traininput, trainlabel in trainloader:\n",
    "            traininputs, trainlabels = traininput.to(device), trainlabel.to(device) \n",
    "            optimizer.zero_grad()\n",
    "            trainpredictions = net(traininputs)\n",
    "            _, trainpredict = torch.max(trainpredictions.data, 1)\n",
    "            loss = loss_function(trainpredictions, trainlabels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            trainloss += loss.item()\n",
    "            traintotal += trainlabels.size(0)\n",
    "            trainsuccessful += (trainpredict == trainlabels).sum().item()\n",
    "        else:\n",
    "            testloss = 0\n",
    "            testtotal = 0\n",
    "            testsuccessful = 0\n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                for testinput, testlabel in testloader:\n",
    "                    testinputs, testlabels = testinput.to(device), testlabel.to(device)\n",
    "                    testpredictions = net(testinputs)\n",
    "                    _, testpredict = torch.max(testpredictions.data, 1)\n",
    "                    tloss = loss_function(testpredictions, testlabels)\n",
    "                    testloss += tloss.item()\n",
    "                    testtotal += testlabels.size(0)\n",
    "                    testsuccessful += (testpredict == testlabels).sum().item()\n",
    "                net.train()\n",
    "\n",
    "            tb.add_scalar('Loss', trainloss/len(trainloader), epoch)        \n",
    "            tb_test.add_scalar('Loss', testloss/len(testloader), epoch)\n",
    "\n",
    "            tb.add_scalar('Accuracy', (100*trainsuccessful/traintotal), epoch)\n",
    "            tb_test.add_scalar('Accuracy', (100*testsuccessful/testtotal), epoch)\n",
    "\n",
    "            if(epoch%2==0):\n",
    "                torch.save({\n",
    "                    'epoch':epoch,\n",
    "                    'model_state_dict': net.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss':loss\n",
    "                },\n",
    "                PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResnetBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResnetBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResnetBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResnetBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResnetBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResnetBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ResnetBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResnetBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResnetBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResnetBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): ResnetBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc1): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert model to onnx\n",
    "PATH=\"image_scene_classification_3ch.pth\"\n",
    "checkpoint = torch.load(PATH)\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for converting the model to onnx. \n",
    "'''\n",
    "x=torch.randn(1,3,80,80,requires_grad=True).to(device)\n",
    "onnx.export(net,\n",
    "           x,\n",
    "           \"scene_classification_ch3.onnx\",\n",
    "           export_params=True,\n",
    "           opset_version=10,\n",
    "           do_constant_folding=True,\n",
    "           input_names =['input'],\n",
    "           output_names = ['output'],\n",
    "           dynamic_axes={'input' : {0: 'batch_size'},\n",
    "                        'output' : {0: 'batch_size'}})\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
